{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在载入 plus 运算符...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5059/5059 [00:21<00:00, 230.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在载入 sub 运算符...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6500/6500 [01:20<00:00, 81.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在载入 mul 运算符...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5102/5102 [01:42<00:00, 49.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在载入 div 运算符...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4234/4234 [01:51<00:00, 37.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在载入 ( 运算符...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6500/6500 [03:39<00:00, 29.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在载入 ) 运算符...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6500/6500 [04:40<00:00, 23.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import queue\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def getListFiles(path):\n",
    "    ret = []\n",
    "    for root, dirs, files in os.walk(path):  \n",
    "        for filespath in files:\n",
    "            ret.append(os.path.join(root,filespath)) \n",
    "    return ret\n",
    "\n",
    "def get_images_labels():\n",
    "    operators = ['plus', 'sub', 'mul', 'div', '(', ')']\n",
    "    images = None\n",
    "    labels = None\n",
    "    for i, op in enumerate(operators):\n",
    "        image_file_list = getListFiles('./cfs/' + op + '/')\n",
    "        print('正在载入 ' + op + ' 运算符...')\n",
    "        for filename in tqdm(image_file_list):\n",
    "            image = cv2.imread(filename, 2)\n",
    "            if image.shape != (28, 28):\n",
    "                image = cv2.resize(image, (28, 28))\n",
    "            image = np.resize(image, (1, 28 * 28))\n",
    "            image = (255 - image) / 255\n",
    "            label = np.zeros((1, 10 + len(operators)))\n",
    "            label[0][10 + i] = 1\n",
    "            if images is None:\n",
    "                images = image\n",
    "                labels = label\n",
    "            else:\n",
    "                images = np.r_[images, image]\n",
    "                labels = np.r_[labels, label]\n",
    "    return images, labels\n",
    "\n",
    "op_images, op_labels = get_images_labels()\n",
    "op_images = op_images.reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\n",
    "trainX = trainX.astype(\"float32\")\n",
    "testX = testX.astype(\"float32\")\n",
    "trainX = trainX/255.0\n",
    "testX = testX/255.0\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "trainY = to_categorical(trainY, 16)\n",
    "testY = to_categorical(testY, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有训练数据： (103895, 28, 28, 1)\n",
      "所有标签数据： (103895, 16)\n"
     ]
    }
   ],
   "source": [
    "dataset   = np.vstack((op_images, trainX, testX))\n",
    "datalabel = np.vstack((op_labels, trainY, testY))\n",
    "\n",
    "dataset = dataset.reshape(-1,28,28,1)\n",
    "print('所有训练数据：',dataset.shape)\n",
    "print('所有标签数据：',datalabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据： (93505, 28, 28, 1) (93505, 16)\n",
      "测试数据： (10390, 28, 28, 1) (10390, 16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(dataset,datalabel,test_size=0.1, random_state=0)\n",
    "print('训练数据：',trainX.shape, trainY.shape)\n",
    "print('测试数据：',testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 28)        7084      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 28)        7084      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 11, 11, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3388)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               867584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 886,144\n",
      "Trainable params: 886,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(28, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(28, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(16,  activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1462/1462 [==============================] - 16s 10ms/step - loss: 0.1171 - accuracy: 0.9656 - val_loss: 0.0436 - val_accuracy: 0.9861\n",
      "Epoch 2/10\n",
      "1462/1462 [==============================] - 13s 9ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.0352 - val_accuracy: 0.9891\n",
      "Epoch 3/10\n",
      "1462/1462 [==============================] - 13s 9ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0379 - val_accuracy: 0.9901\n",
      "Epoch 4/10\n",
      "1462/1462 [==============================] - 13s 9ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.0329 - val_accuracy: 0.9913\n",
      "Epoch 5/10\n",
      "1462/1462 [==============================] - 13s 9ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0311 - val_accuracy: 0.9920\n",
      "Epoch 6/10\n",
      "1462/1462 [==============================] - 13s 9ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0349 - val_accuracy: 0.9920\n",
      "Epoch 7/10\n",
      "1462/1462 [==============================] - 13s 9ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0394 - val_accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "1462/1462 [==============================] - 13s 9ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0317 - val_accuracy: 0.9924\n",
      "Epoch 9/10\n",
      "1462/1462 [==============================] - 13s 9ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0431 - val_accuracy: 0.9912\n",
      "Epoch 10/10\n",
      "1462/1462 [==============================] - 13s 9ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0384 - val_accuracy: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f14031fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY ,batch_size=64 ,epochs = 10 ,verbose=1,validation_data=(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value is 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "pixels = testX[random.randint(0,len(testX)-1)]\n",
    "pixels = np.expand_dims(pixels, axis=0)\n",
    "pyplot.imshow(pixels.reshape(28,28),cmap='gray')\n",
    "prediction = model.predict(pixels)\n",
    "index = np.argmax(prediction[0])\n",
    "print(\"predicted value is \"+str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "new_model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value is 6 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "pixels = testX[random.randint(0,len(testX)-1)]\n",
    "pixels = np.expand_dims(pixels, axis=0)\n",
    "pyplot.imshow(pixels.reshape(28,28), cmap='gray')\n",
    "pixels = pixels.reshape(-1,28,28,1)\n",
    "\n",
    "prediction = new_model.predict(pixels)\n",
    "index = np.argmax(prediction[0])\n",
    "print(\"predicted value is \"+str(index), prediction[0][index])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
